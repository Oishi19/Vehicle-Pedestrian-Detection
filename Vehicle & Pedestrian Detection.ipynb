{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle & Pedestrian Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedestrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create our body classifier\n",
    "body_classifier = cv2.CascadeClassifier('Computer-Vision-Tutorial-master\\Haarcascades\\haarcascade_fullbody.xml')\n",
    "\n",
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('Computer-Vision-Tutorial-master/image_examples/walking.avi')\n",
    "\n",
    "# Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    #frame = cv2.resize(frame, None,fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Pass frame to our body classifier\n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        cv2.imshow('Pedestrians', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Create our body classifier\n",
    "car_classifier = cv2.CascadeClassifier('Haarcascades\\haarcascade_car.xml')\n",
    "\n",
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('Computer-Vision-Tutorial-master/image_examples/cars.avi')\n",
    "\n",
    "\n",
    "# Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    time.sleep(.05)\n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        cv2.imshow('Cars', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5ce9a5a87c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;31m# Import the OpenCV library to enable computer vision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# Import the NumPy scientific computing library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_detection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnon_max_suppression\u001b[0m \u001b[1;31m# Handle overlapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Make sure the video file is in the same directory as your code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import cv2 # Import the OpenCV library to enable computer vision\n",
    "import numpy as np # Import the NumPy scientific computing library\n",
    "from imutils.object_detection import non_max_suppression # Handle overlapping\n",
    " \n",
    "# Make sure the video file is in the same directory as your code\n",
    "filename = 'Computer-Vision-Tutorial-master/image_examples/cars.avi'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "scale_ratio = 1 # Option to scale to fraction of original size. \n",
    " \n",
    "# We want to save the output to a video file\n",
    "output_filename = 'pedestrians_on_street.mp4'\n",
    "output_frames_per_second = 20.0\n",
    " \n",
    "def main():\n",
    " \n",
    "  # Create a HOGDescriptor object\n",
    "  hog = cv2.HOGDescriptor()\n",
    "     \n",
    "  # Initialize the People Detector\n",
    "  hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "     \n",
    "  # Load a video\n",
    "  cap = cv2.VideoCapture(filename)\n",
    " \n",
    "  # Create a VideoWriter object so we can save the video output\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  result = cv2.VideoWriter(output_filename,  \n",
    "                           fourcc, \n",
    "                           output_frames_per_second, \n",
    "                           file_size) \n",
    "     \n",
    "  # Process the video\n",
    "  while cap.isOpened():\n",
    "         \n",
    "    # Capture one frame at a time\n",
    "    success, frame = cap.read() \n",
    "         \n",
    "    # Do we have a video frame? If true, proceed.\n",
    "    if success:\n",
    "         \n",
    "        # Resize the frame\n",
    "      width = int(frame.shape[1] * scale_ratio)\n",
    "      height = int(frame.shape[0] * scale_ratio)\n",
    "      frame = cv2.resize(frame, (width, height))\n",
    "             \n",
    "      # Store the original frame\n",
    "      orig_frame = frame.copy()\n",
    "             \n",
    "      # Detect people\n",
    "      # image: a single frame from the video\n",
    "      # winStride: step size in x and y direction of the sliding window\n",
    "      # padding: no. of pixels in x and y direction for padding of \n",
    "      # sliding window\n",
    "      # scale: Detection window size increase coefficient   \n",
    "      # bounding_boxes: Location of detected people\n",
    "      # weights: Weight scores of detected people\n",
    "      # Tweak these parameters for better results\n",
    "      (bounding_boxes, weights) = hog.detectMultiScale(frame, \n",
    "                                                       winStride=(16, 16),\n",
    "                                                       padding=(4, 4), \n",
    "                                                       scale=1.05)\n",
    " \n",
    "      # Draw bounding boxes on the frame\n",
    "      for (x, y, w, h) in bounding_boxes: \n",
    "            cv2.rectangle(orig_frame, \n",
    "            (x, y),  \n",
    "            (x + w, y + h),  \n",
    "            (0, 0, 255), \n",
    "             2)\n",
    "                         \n",
    "      # Get rid of overlapping bounding boxes\n",
    "      # You can tweak the overlapThresh value for better results\n",
    "      bounding_boxes = np.array([[x, y, x + w, y + h] for (\n",
    "                                x, y, w, h) in bounding_boxes])\n",
    "             \n",
    "      selection = non_max_suppression(bounding_boxes, \n",
    "                                      probs=None, \n",
    "                                      overlapThresh=0.45)\n",
    "         \n",
    "      # draw the final bounding boxes\n",
    "      for (x1, y1, x2, y2) in selection:\n",
    "        cv2.rectangle(frame, \n",
    "                     (x1, y1), \n",
    "                     (x2, y2), \n",
    "                     (0, 255, 0), \n",
    "                      4)\n",
    "         \n",
    "      # Write the frame to the output video file\n",
    "      result.write(frame)\n",
    "             \n",
    "      # Display the frame \n",
    "      cv2.imshow(\"Frame\", frame)    \n",
    " \n",
    "      # Display frame for X milliseconds and check if q key is pressed\n",
    "      # q == quit\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "         \n",
    "    # No more video frames left\n",
    "    else:\n",
    "      break\n",
    "             \n",
    "  # Stop when the video is finished\n",
    "  cap.release()\n",
    "     \n",
    "  # Release the video recording\n",
    "  result.release()\n",
    "     \n",
    "  # Close all windows\n",
    "  cv2.destroyAllWindows() \n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
